<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Distance in Multivariate Analysis | STAT 372 Open Textbook (R)</title>
  <meta name="description" content="This is an open textbook resource for the STAT372 course at MacEwan University, an introduction to Multivariate Statistics and Machine Learning." />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Distance in Multivariate Analysis | STAT 372 Open Textbook (R)" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is an open textbook resource for the STAT372 course at MacEwan University, an introduction to Multivariate Statistics and Machine Learning." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Distance in Multivariate Analysis | STAT 372 Open Textbook (R)" />
  
  <meta name="twitter:description" content="This is an open textbook resource for the STAT372 course at MacEwan University, an introduction to Multivariate Statistics and Machine Learning." />
  

<meta name="author" content="Dr.Â Wanhua Su" />


<meta name="date" content="2024-04-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="displaying-multivariate-data-and-measures-of-distance.html"/>
<link rel="next" href="multivariate-normal-distribution.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preamble</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#learning-outcomes"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#introduction"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#some-examples"><i class="fa fa-check"></i><b>2.2</b> Some Examples</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#example-1-storm-survival-of-sparrows"><i class="fa fa-check"></i>Example 1: Storm Survival of Sparrows</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#example-2-spam-or-e-mail"><i class="fa fa-check"></i>Example 2: Spam or E-mail?</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#example-3-classification-of-iris"><i class="fa fa-check"></i>Example 3: Classification of Iris</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#multivariate-methods-covered-in-stat-372"><i class="fa fa-check"></i><b>2.3</b> Multivariate Methods Covered in STAT 372</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#review-univariate-analysis"><i class="fa fa-check"></i><b>2.4</b> Review: Univariate Analysis</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="intro.html"><a href="intro.html#random-variable-and-its-distribution"><i class="fa fa-check"></i><b>2.4.1</b> Random Variable and Its Distribution</a></li>
<li class="chapter" data-level="2.4.2" data-path="intro.html"><a href="intro.html#properties-of-expectation-and-variance"><i class="fa fa-check"></i><b>2.4.2</b> Properties of Expectation and Variance</a></li>
<li class="chapter" data-level="2.4.3" data-path="intro.html"><a href="intro.html#continuous-random-variables"><i class="fa fa-check"></i><b>2.4.3</b> Continuous Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#revisit-learning-learning-outcomes"><i class="fa fa-check"></i>Revisit Learning Learning Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="matrix-algebra.html"><a href="matrix-algebra.html"><i class="fa fa-check"></i><b>3</b> Matrix Algebra</a>
<ul>
<li class="chapter" data-level="" data-path="matrix-algebra.html"><a href="matrix-algebra.html#learning-outcomes-1"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="3.1" data-path="matrix-algebra.html"><a href="matrix-algebra.html#vectors"><i class="fa fa-check"></i><b>3.1</b> Vectors</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="matrix-algebra.html"><a href="matrix-algebra.html#some-basic-operations-on-vectors"><i class="fa fa-check"></i><b>3.1.1</b> Some Basic Operations on Vectors</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="matrix-algebra.html"><a href="matrix-algebra.html#matrices"><i class="fa fa-check"></i><b>3.2</b> Matrices</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="matrix-algebra.html"><a href="matrix-algebra.html#basic-operations-on-matrix"><i class="fa fa-check"></i><b>3.2.1</b> Basic Operations on Matrix</a></li>
<li class="chapter" data-level="3.2.2" data-path="matrix-algebra.html"><a href="matrix-algebra.html#eigenvalues-and-eigenvectors"><i class="fa fa-check"></i><b>3.2.2</b> Eigenvalues and Eigenvectors</a></li>
<li class="chapter" data-level="3.2.3" data-path="matrix-algebra.html"><a href="matrix-algebra.html#spectral-eigen-decomposition"><i class="fa fa-check"></i><b>3.2.3</b> Spectral (Eigen) Decomposition</a></li>
<li class="chapter" data-level="3.2.4" data-path="matrix-algebra.html"><a href="matrix-algebra.html#singular-value-decomposition"><i class="fa fa-check"></i><b>3.2.4</b> Singular-Value Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="matrix-algebra.html"><a href="matrix-algebra.html#mean-vectors-and-covariance-matrices"><i class="fa fa-check"></i><b>3.3</b> Mean Vectors and Covariance Matrices</a></li>
<li class="chapter" data-level="3.4" data-path="matrix-algebra.html"><a href="matrix-algebra.html#sample-mean-vector-and-covariance-matrix"><i class="fa fa-check"></i><b>3.4</b> Sample Mean Vector and Covariance Matrix</a></li>
<li class="chapter" data-level="3.5" data-path="matrix-algebra.html"><a href="matrix-algebra.html#review-exercises"><i class="fa fa-check"></i><b>3.5</b> Review Exercises</a></li>
<li class="chapter" data-level="" data-path="matrix-algebra.html"><a href="matrix-algebra.html#revisit-the-learning-outcomes"><i class="fa fa-check"></i>Revisit the Learning Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="displaying-multivariate-data-and-measures-of-distance.html"><a href="displaying-multivariate-data-and-measures-of-distance.html"><i class="fa fa-check"></i><b>4</b> Displaying Multivariate Data and Measures of Distance</a>
<ul>
<li class="chapter" data-level="" data-path="displaying-multivariate-data-and-measures-of-distance.html"><a href="displaying-multivariate-data-and-measures-of-distance.html#learning-learning-outcomes"><i class="fa fa-check"></i>Learning Learning Outcomes</a></li>
<li class="chapter" data-level="4.1" data-path="displaying-multivariate-data-and-measures-of-distance.html"><a href="displaying-multivariate-data-and-measures-of-distance.html#display-multivariate-data"><i class="fa fa-check"></i><b>4.1</b> Display Multivariate Data</a></li>
<li class="chapter" data-level="4.2" data-path="displaying-multivariate-data-and-measures-of-distance.html"><a href="displaying-multivariate-data-and-measures-of-distance.html#scatterplot"><i class="fa fa-check"></i><b>4.2</b> Scatterplot</a></li>
<li class="chapter" data-level="4.3" data-path="displaying-multivariate-data-and-measures-of-distance.html"><a href="displaying-multivariate-data-and-measures-of-distance.html#graphs-of-growth-curves"><i class="fa fa-check"></i><b>4.3</b> Graphs of Growth Curves</a></li>
<li class="chapter" data-level="4.4" data-path="displaying-multivariate-data-and-measures-of-distance.html"><a href="displaying-multivariate-data-and-measures-of-distance.html#star-plots"><i class="fa fa-check"></i><b>4.4</b> Star Plots</a></li>
<li class="chapter" data-level="4.5" data-path="displaying-multivariate-data-and-measures-of-distance.html"><a href="displaying-multivariate-data-and-measures-of-distance.html#chernoff-faces-plot"><i class="fa fa-check"></i><b>4.5</b> Chernoff Faces Plot</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="distance-in-multivariate-analysis.html"><a href="distance-in-multivariate-analysis.html"><i class="fa fa-check"></i><b>5</b> Distance in Multivariate Analysis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="distance-in-multivariate-analysis.html"><a href="distance-in-multivariate-analysis.html#distances-for-quantitative-variables"><i class="fa fa-check"></i><b>5.1</b> Distances for Quantitative Variables</a></li>
<li class="chapter" data-level="5.2" data-path="distance-in-multivariate-analysis.html"><a href="distance-in-multivariate-analysis.html#distance-for-categorical-variables"><i class="fa fa-check"></i><b>5.2</b> Distance for Categorical Variables</a></li>
<li class="chapter" data-level="5.3" data-path="distance-in-multivariate-analysis.html"><a href="distance-in-multivariate-analysis.html#distance-for-mixed-variable-types"><i class="fa fa-check"></i><b>5.3</b> Distance for Mixed Variable Types</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivariate-normal-distribution.html"><a href="multivariate-normal-distribution.html"><i class="fa fa-check"></i><b>6</b> Multivariate Normal Distribution</a>
<ul>
<li class="chapter" data-level="6.1" data-path="multivariate-normal-distribution.html"><a href="multivariate-normal-distribution.html#properties-of-multivariate-normal-distribution"><i class="fa fa-check"></i><b>6.1</b> Properties of Multivariate Normal Distribution</a></li>
<li class="chapter" data-level="6.2" data-path="multivariate-normal-distribution.html"><a href="multivariate-normal-distribution.html#bivariate-normal-distribution"><i class="fa fa-check"></i><b>6.2</b> Bivariate Normal Distribution</a></li>
<li class="chapter" data-level="6.3" data-path="multivariate-normal-distribution.html"><a href="multivariate-normal-distribution.html#contour-of-multivariate-normal-distribution"><i class="fa fa-check"></i><b>6.3</b> Contour of Multivariate Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="the-sampling-distribution-of-myvecbar-x-and-gvecs.html"><a href="the-sampling-distribution-of-myvecbar-x-and-gvecs.html"><i class="fa fa-check"></i><b>7</b> The Sampling Distribution of <span class="math inline">\(\myvec{\bar X}\)</span> and <span class="math inline">\(\gvec{S}\)</span></a>
<ul>
<li class="chapter" data-level="7.1" data-path="the-sampling-distribution-of-myvecbar-x-and-gvecs.html"><a href="the-sampling-distribution-of-myvecbar-x-and-gvecs.html#distributions-related-to-normal-distribution"><i class="fa fa-check"></i><b>7.1</b> Distributions Related to Normal Distribution</a></li>
<li class="chapter" data-level="7.2" data-path="the-sampling-distribution-of-myvecbar-x-and-gvecs.html"><a href="the-sampling-distribution-of-myvecbar-x-and-gvecs.html#applications-to-distributions-related-to-sample-means"><i class="fa fa-check"></i><b>7.2</b> Applications to Distributions Related to Sample Means</a></li>
<li class="chapter" data-level="7.3" data-path="the-sampling-distribution-of-myvecbar-x-and-gvecs.html"><a href="the-sampling-distribution-of-myvecbar-x-and-gvecs.html#generalize-to-multivariate-cases"><i class="fa fa-check"></i><b>7.3</b> Generalize to Multivariate Cases</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="review-exercises-1.html"><a href="review-exercises-1.html"><i class="fa fa-check"></i><b>8</b> Review Exercises</a></li>
<li class="chapter" data-level="" data-path="revisit-the-learning-outcomes-1.html"><a href="revisit-the-learning-outcomes-1.html"><i class="fa fa-check"></i>Revisit the Learning Outcomes</a></li>
<li class="chapter" data-level="9" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html"><i class="fa fa-check"></i><b>9</b> Hypothesis Tests on Mean Vectors</a>
<ul>
<li class="chapter" data-level="9.1" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#univariate-case"><i class="fa fa-check"></i><b>9.1</b> Univariate Case</a></li>
<li class="chapter" data-level="9.2" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#multivariate-case"><i class="fa fa-check"></i><b>9.2</b> Multivariate Case</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#one-sample-hotellings-t2-test"><i class="fa fa-check"></i>One-sample Hotellingâs <span class="math inline">\(T^2\)</span> Test</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#one-sample-hotellings-t2-confidence-interval"><i class="fa fa-check"></i>One-sample Hotellingâs <span class="math inline">\(T^2\)</span> Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#evaluating-multivariate-normality"><i class="fa fa-check"></i><b>9.3</b> Evaluating Multivariate Normality</a></li>
<li class="chapter" data-level="9.4" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#univariate-case-based-on-two-independent-samples"><i class="fa fa-check"></i><b>9.4</b> Univariate Case Based on Two Independent Samples</a></li>
<li class="chapter" data-level="9.5" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#multivariate-case-based-on-two-independent-samples"><i class="fa fa-check"></i><b>9.5</b> Multivariate Case Based on Two Independent Samples</a></li>
<li class="chapter" data-level="9.6" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#two-sample-non-pooled-hotellings-t2-test"><i class="fa fa-check"></i><b>9.6</b> Two-sample Non-pooled Hotellingâs <span class="math inline">\(T^2\)</span> Test</a></li>
<li class="chapter" data-level="9.7" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#two-sample-hotellings-t2-confidence-interval"><i class="fa fa-check"></i><b>9.7</b> Two-sample Hotellingâs <span class="math inline">\(T^2\)</span> Confidence Interval</a></li>
<li class="chapter" data-level="9.8" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#univariate-case-based-on-a-paired-sample"><i class="fa fa-check"></i><b>9.8</b> Univariate Case Based on a Paired Sample</a></li>
<li class="chapter" data-level="9.9" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#multivariate-case-based-on-a-paired-sample"><i class="fa fa-check"></i><b>9.9</b> Multivariate Case Based on a Paired Sample</a></li>
<li class="chapter" data-level="9.10" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#univariate-case-one-way-anova-f-test"><i class="fa fa-check"></i><b>9.10</b> Univariate Case: One-Way ANOVA F Test</a></li>
<li class="chapter" data-level="9.11" data-path="hypothesis-tests-on-mean-vectors.html"><a href="hypothesis-tests-on-mean-vectors.html#multivariate-case-one-way-manova"><i class="fa fa-check"></i><b>9.11</b> Multivariate Case: One-Way MANOVA</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>10</b> Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#learning-outcomes-2"><i class="fa fa-check"></i>Learning Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>11</b> Factor Analysis</a></li>
<li class="chapter" data-level="12" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html"><i class="fa fa-check"></i><b>12</b> Discriminant Analysis and Classification</a>
<ul>
<li class="chapter" data-level="" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#learning-outcomes-3"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="12.1" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#introduction-1"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#overfitting-and-cross-validation"><i class="fa fa-check"></i><b>12.2</b> Overfitting and Cross Validation</a></li>
<li class="chapter" data-level="12.3" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#classification-models"><i class="fa fa-check"></i><b>12.3</b> Classification Models</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>12.3.1</b> <span class="math inline">\(K\)</span> Nearest Neighbors</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#logistic-regression-for-binary-response"><i class="fa fa-check"></i><b>12.4</b> Logistic Regression for Binary Response</a>
<ul>
<li class="chapter" data-level="" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#interpretation-of-beta_i"><i class="fa fa-check"></i>Interpretation of <span class="math inline">\(\beta_i\)</span></a></li>
<li class="chapter" data-level="" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#estimation-of-beta_i"><i class="fa fa-check"></i>Estimation of <span class="math inline">\(\beta_i\)</span></a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#logistic-regression-for-multi-class-nominal-data"><i class="fa fa-check"></i><b>12.5</b> Logistic Regression for Multi-class Nominal Data</a></li>
<li class="chapter" data-level="12.6" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#cumulative-logit-model-for-multi-class-ordinal-data"><i class="fa fa-check"></i><b>12.6</b> Cumulative Logit Model for Multi-class Ordinal Data</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#cumulative-logit-models-with-proportional-odds"><i class="fa fa-check"></i><b>12.6.1</b> Cumulative Logit Models with Proportional Odds</a></li>
<li class="chapter" data-level="12.6.2" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#model-probability-of-each-category"><i class="fa fa-check"></i><b>12.6.2</b> Model Probability of Each Category</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#model-selection-for-logistic-regression"><i class="fa fa-check"></i><b>12.7</b> Model Selection for Logistic Regression</a>
<ul>
<li class="chapter" data-level="12.7.1" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#aic-and-bic"><i class="fa fa-check"></i><b>12.7.1</b> AIC and BIC</a></li>
<li class="chapter" data-level="12.7.2" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#forward-selection"><i class="fa fa-check"></i><b>12.7.2</b> Forward Selection</a></li>
<li class="chapter" data-level="12.7.3" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#backward-elimination"><i class="fa fa-check"></i><b>12.7.3</b> Backward Elimination</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#model-checking"><i class="fa fa-check"></i><b>12.8</b> Model Checking</a>
<ul>
<li class="chapter" data-level="12.8.1" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#residual-analysis"><i class="fa fa-check"></i><b>12.8.1</b> Residual Analysis</a></li>
<li class="chapter" data-level="12.8.2" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#preditive-power-accuracy-and-roc-curve"><i class="fa fa-check"></i><b>12.8.2</b> Preditive Power: Accuracy and ROC Curve</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#classification-tree-recursive-partitioning"><i class="fa fa-check"></i><b>12.9</b> Classification Tree (Recursive Partitioning)</a></li>
<li class="chapter" data-level="12.10" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#regression-tree"><i class="fa fa-check"></i><b>12.10</b> Regression Tree</a></li>
<li class="chapter" data-level="12.11" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#random-forest"><i class="fa fa-check"></i><b>12.11</b> Random Forest</a></li>
<li class="chapter" data-level="12.12" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#support-vector-machines"><i class="fa fa-check"></i><b>12.12</b> Support Vector Machines</a></li>
<li class="chapter" data-level="12.13" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#neural-networks"><i class="fa fa-check"></i><b>12.13</b> Neural Networks</a></li>
<li class="chapter" data-level="12.14" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#mahalanobis-distance-method"><i class="fa fa-check"></i><b>12.14</b> Mahalanobis Distance Method</a></li>
<li class="chapter" data-level="12.15" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#bayes-posterior"><i class="fa fa-check"></i><b>12.15</b> Bayes Posterior</a></li>
<li class="chapter" data-level="12.16" data-path="discriminant-analysis-and-classification.html"><a href="discriminant-analysis-and-classification.html#fishers-discriminant-analysis"><i class="fa fa-check"></i><b>12.16</b> Fisherâs Discriminant Analysis</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="clustering-analysis.html"><a href="clustering-analysis.html"><i class="fa fa-check"></i><b>13</b> Clustering Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="clustering-analysis.html"><a href="clustering-analysis.html#learning-outcomes-4"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="13.1" data-path="clustering-analysis.html"><a href="clustering-analysis.html#introduction-2"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="clustering-analysis.html"><a href="clustering-analysis.html#clustering-methods"><i class="fa fa-check"></i><b>13.2</b> Clustering Methods</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="clustering-analysis.html"><a href="clustering-analysis.html#hierarchical-method"><i class="fa fa-check"></i><b>13.2.1</b> Hierarchical Method</a></li>
<li class="chapter" data-level="13.2.2" data-path="clustering-analysis.html"><a href="clustering-analysis.html#k-means"><i class="fa fa-check"></i><b>13.2.2</b> K-Means</a></li>
<li class="chapter" data-level="13.2.3" data-path="clustering-analysis.html"><a href="clustering-analysis.html#model-based-clustering"><i class="fa fa-check"></i><b>13.2.3</b> Model-Based Clustering</a></li>
<li class="chapter" data-level="13.2.4" data-path="clustering-analysis.html"><a href="clustering-analysis.html#pros-and-cons-of-clustering-methods"><i class="fa fa-check"></i><b>13.2.4</b> Pros and Cons of Clustering Methods</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="clustering-analysis.html"><a href="clustering-analysis.html#determine-k-number-of-clusters"><i class="fa fa-check"></i><b>13.3</b> Determine <span class="math inline">\(K\)</span>: Number of Clusters</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="clustering-analysis.html"><a href="clustering-analysis.html#the-elbow-plot-method"><i class="fa fa-check"></i><b>13.3.1</b> The Elbow Plot Method</a></li>
<li class="chapter" data-level="13.3.2" data-path="clustering-analysis.html"><a href="clustering-analysis.html#the-silhouette-score"><i class="fa fa-check"></i><b>13.3.2</b> The Silhouette Score</a></li>
<li class="chapter" data-level="13.3.3" data-path="clustering-analysis.html"><a href="clustering-analysis.html#gap-statistics"><i class="fa fa-check"></i><b>13.3.3</b> Gap Statistics</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="clustering-analysis.html"><a href="clustering-analysis.html#side-note-on-the-em-algorithm"><i class="fa fa-check"></i>Side-Note on the EM Algorithm</a></li>
<li class="chapter" data-level="" data-path="clustering-analysis.html"><a href="clustering-analysis.html#revisit-learning-outcomes"><i class="fa fa-check"></i>Revisit Learning Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="canonical-correlation-analysis.html"><a href="canonical-correlation-analysis.html"><i class="fa fa-check"></i><b>14</b> Canonical Correlation Analysis</a>
<ul>
<li class="chapter" data-level="" data-path="canonical-correlation-analysis.html"><a href="canonical-correlation-analysis.html#learning-outcomes-5"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="" data-path="canonical-correlation-analysis.html"><a href="canonical-correlation-analysis.html#revisit-learning-outcomes-1"><i class="fa fa-check"></i>Revisit Learning Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="multidimensional-scaling.html"><a href="multidimensional-scaling.html"><i class="fa fa-check"></i><b>15</b> Multidimensional Scaling</a>
<ul>
<li class="chapter" data-level="" data-path="multidimensional-scaling.html"><a href="multidimensional-scaling.html#learning-outcomes-6"><i class="fa fa-check"></i>Learning Outcomes</a></li>
<li class="chapter" data-level="" data-path="multidimensional-scaling.html"><a href="multidimensional-scaling.html#revisit-learning-outcomes-2"><i class="fa fa-check"></i>Revisit Learning Outcomes</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 372 Open Textbook (R)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="distance-in-multivariate-analysis" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> Distance in Multivariate Analysis<a href="distance-in-multivariate-analysis.html#distance-in-multivariate-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In multivariate analysis, most methods are based on the simple concept of distance. Take clustering analysis for example, we need to group observations that are similar or close to one another. Therefore, we need to calculate the distance between the observations.</p>
<div id="distances-for-quantitative-variables" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Distances for Quantitative Variables<a href="distance-in-multivariate-analysis.html#distances-for-quantitative-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In univariate cases, the distance between two observations <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> is defined as <span class="math inline">\(d(x_1,x_2)=|x_1-x_2|=\sqrt{(x_1-x_2)^2}\)</span>. This definition can be extended to the multivariate cases. Suppose <span class="math inline">\(\mathbf{x}=[x_1, x_2, \cdots, x_n]^{T}\)</span> and <span class="math inline">\(\mathbf{y}=[y_1, y_2, \cdots, y_n]^{T}\)</span> are two vectors, their <em>Euclidean</em> distance is defined as
<span class="math display">\[
d(\mathbf{x}, \mathbf{y})=\sqrt{(x_1-y_1)^2+(x_2-y_2)^2+\cdots+(x_n-y_n)^2}=\sqrt{(\mathbf{x}-\mathbf{y})^{T}(\mathbf{x}-\mathbf{y})}.
\]</span>
And the <em>Manhattan</em> distance is defined as
<span class="math display">\[
d(\mathbf{x}, \mathbf{y})=|x_1-y_1|+|x_2-y_2|+\cdots+|x_n-y_n|=\dsum_{i=1}^n |x_i-y_i|.
\]</span></p>
<p>The <em>Minkowski</em> distance is defined as
<span class="math display">\[
d(\mathbf{x}, \mathbf{y})=\left(\dsum_{i=1}^n |x_i-y_i|^p\right)^{1/p},
\]</span>
which includes the Manhattan distance (when <span class="math inline">\(p=1\)</span>) and the Euclidean distance (when <span class="math inline">\(p=2\)</span>) as special cases.</p>
<p>Euclidean distance treats each coordinate equally without accounting for the amount of variability in each dimension. A measure that does take into account the variance and covariance of the variables is the <em>Mahalanobis</em> distance
<span class="math display">\[
d(\mathbf{x}, \mathbf{y})=\sqrt{(\mathbf{x}-\mathbf{y})^{T}\mathbf{\Sigma}^{-1}(\mathbf{x}-\mathbf{y})}
\]</span>
where <span class="math inline">\(\mathbf{\Sigma}\)</span> is the variance-covariance matrix which can be replaced by the sample variance-covariance matrix if it is unknown.</p>
One can define his own way to calculate distance as long as the function <span class="math inline">\(d(.)\)</span> satisfies the following properties:
<p><strong>Note</strong>: If a ``unit changeââ means dramatically different things for different variables, we shall standardize the measurements by subtracting its mean and dividing its standard deviation before we calculate the distance.</p>
<p><strong>Example</strong>: Verify that the Euclidean distance is a valid distance merit.
</p>
</div>
<div id="distance-for-categorical-variables" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Distance for Categorical Variables<a href="distance-in-multivariate-analysis.html#distance-for-categorical-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For categorical variables whose values are categories, it is meaningless to calculate the distance using the functions given in the previous section. For example, there are four possible blood types: A, B, O, AB. Even though we can recode the values as 1=A, 2=B, 3=O and 4=AB, we would not say that the distance between types A and B is closer than the distance between types A and O. For categorical measurements, we can use the <em>Hamming</em> distance
<span class="math display">\[
d(\mathbf{x}, \mathbf{y})=\sum_{i=1}^p \mbox{I}(x_i\ne y_i),
\]</span>
where I(.) is an indicator function which takes the value 1 if the statement is true otherwise 0. Hamming distance between two observations counts the number of not-matched measurements. For example,</p>
<p>The Hamming distance between Kate and John is 2 and between Kate and Adam is 1. One can also standardize the Hamming distance by dividing the number of categorical variables. That is
<span class="math display">\[
d(\mathbf{x}, \mathbf{y})=\frac{\sum_{i=1}^p \mbox{I}(x_i\ne y_i)}{p}.
\]</span></p>
<p>One special categorical variable is the <em>binary</em> variable which takes only two possible values: 0 (a certain attribute absent) or 1(a certain attribute present). A binary variable is called <em>asymmetric</em> if one of the two states (e.g.Â state â0â) is interpreted as more informative than the other state. For example, Married (1) or Not Married (0); not married can be single, divorced or widowed. If both observations have value ``0ââ, we can not say if they are the same or different. Therefore, for asymmetric binary variable, the distance can be calculated as
<span class="math display">\[
d(\mathbf{x}, \mathbf{y})=\frac{\sum_{i=1}^p \mbox{I}(x_i\ne y_i)}{p-\mbox{\# of 0-0 pairs} }
\]</span>
this is also called the <em>Jaccard coefficient</em>.</p>
</div>
<div id="distance-for-mixed-variable-types" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Distance for Mixed Variable Types<a href="distance-in-multivariate-analysis.html#distance-for-mixed-variable-types" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When the multivariate measurements are mixed of quantitative and categorical data, <em>Gowerâs coefficient</em> can be calculated to measure the distance between two observations:
<span class="math display">\[
  d(\mathbf{x_i}, \mathbf{x_j})=\frac{\sum_{k=1}^p \delta_{ijk}d_{ijk}}{\sum_{k=1}^p \delta_{ijk}}
  \]</span>
where
<span class="math display">\[
\delta_{ijk}=\left\{
\begin{array}{ll}
1&amp;\mbox{if we could use the variable $k$ to compare observations $i$ and $j$},\\
0&amp;\mbox{if we could not tell whether observations $i$ and $j$ are the same or not using variable $k$}.
\end{array}
\right.
\]</span>
and
<span class="math display">\[
d_{ijk}=\left\{
\begin{array}{ll}
\frac{|x_{ik}-x_{jk}|}{\mbox{range of variable $k$}} &amp;\mbox{for quantitative variables},\\
\mbox{I}(x_{ik}\ne x_{jk})&amp;\mbox{for categorical variables}.
\end{array}
\right.
\]</span></p>
<p>To summarize, <span class="math inline">\(\delta_{ijk}=0\)</span> for only 0-0 pairs of asymmetric binary variables.</p>
<p><strong>Example: Gowerâs Coefficient</strong></p>
<p>Find the Gowerâs coefficients for the following three individuals:</p>
<p>Among the categorical variables , , , is asymmetric binary. We can construct a working table to find the distance between the observations.
</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="distance-in-multivariate-analysis.html#cb6-1" tabindex="-1"></a>gender <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">c</span>(<span class="st">&quot;F&quot;</span>,<span class="st">&quot;M&quot;</span>, <span class="st">&quot;M&quot;</span>))</span>
<span id="cb6-2"><a href="distance-in-multivariate-analysis.html#cb6-2" tabindex="-1"></a>haircolor <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">c</span>(<span class="st">&quot;Brown&quot;</span>,<span class="st">&quot;Grey&quot;</span>,<span class="st">&quot;Brown&quot;</span>))</span>
<span id="cb6-3"><a href="distance-in-multivariate-analysis.html#cb6-3" tabindex="-1"></a>asian <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>)</span>
<span id="cb6-4"><a href="distance-in-multivariate-analysis.html#cb6-4" tabindex="-1"></a>height <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">60</span>,<span class="dv">50</span>,<span class="dv">70</span>)</span>
<span id="cb6-5"><a href="distance-in-multivariate-analysis.html#cb6-5" tabindex="-1"></a>weight <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">80</span>,<span class="dv">60</span>,<span class="dv">90</span>)</span>
<span id="cb6-6"><a href="distance-in-multivariate-analysis.html#cb6-6" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">gender=</span>gender,<span class="at">haircolor=</span>haircolor,<span class="at">race=</span>asian,<span class="at">height=</span>height,<span class="at">weight=</span>weight)</span>
<span id="cb6-7"><a href="distance-in-multivariate-analysis.html#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="distance-in-multivariate-analysis.html#cb6-8" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb6-9"><a href="distance-in-multivariate-analysis.html#cb6-9" tabindex="-1"></a><span class="fu">daisy</span>(df, <span class="at">metric =</span> <span class="st">&quot;gower&quot;</span>) <span class="co">#not correct without indicating asymmetric binary</span></span></code></pre></div>
<pre><code>## Dissimilarities :
##           1         2
## 2 0.8333333          
## 3 0.5666667 0.6000000
## 
## Metric :  mixed ;  Types = N, N, I, I, I 
## Number of objects : 3</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="distance-in-multivariate-analysis.html#cb8-1" tabindex="-1"></a><span class="fu">daisy</span>(df,<span class="at">metric =</span> <span class="st">&quot;gower&quot;</span>, <span class="at">type=</span><span class="fu">list</span>(<span class="at">asymm =</span><span class="dv">3</span>, <span class="at">symm=</span><span class="dv">1</span>))</span></code></pre></div>
<pre><code>## Dissimilarities :
##           1         2
## 2 0.8333333          
## 3 0.5666667 0.7500000
## 
## Metric :  mixed ;  Types = S, N, A, I, I 
## Number of objects : 3</code></pre>
<p>If we were told the range of height is 30 and the range of weight is 50 instead, we can create a fake observation to tell the information. For the previous example, we need to create a new observation with height=80 and weight=110, so the range of height is 80-50=30 and range for weight is 110-60=50. For the computer output, just ignore the distance between everyone to the fake person.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="distance-in-multivariate-analysis.html#cb10-1" tabindex="-1"></a>fake <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">gender=</span><span class="fu">as.factor</span>(<span class="st">&quot;F&quot;</span>), <span class="at">haircolor=</span><span class="fu">as.factor</span>(<span class="st">&quot;Black&quot;</span>),<span class="at">race=</span><span class="dv">1</span>, <span class="at">height=</span><span class="dv">80</span>, <span class="at">weight=</span><span class="dv">110</span>)</span>
<span id="cb10-2"><a href="distance-in-multivariate-analysis.html#cb10-2" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> <span class="fu">rbind</span>(df, fake)</span>
<span id="cb10-3"><a href="distance-in-multivariate-analysis.html#cb10-3" tabindex="-1"></a><span class="fu">daisy</span>(df1,<span class="at">metric =</span> <span class="st">&quot;gower&quot;</span>, <span class="at">type=</span><span class="fu">list</span>(<span class="at">asymm =</span><span class="dv">3</span>, <span class="at">symm=</span><span class="dv">1</span>))</span></code></pre></div>
<pre><code>## Dissimilarities :
##           1         2         3
## 2 0.7466667                    
## 3 0.5066667 0.5666667          
## 4 0.4533333 1.0000000 0.7466667
## 
## Metric :  mixed ;  Types = S, N, A, I, I 
## Number of objects : 4</code></pre>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="displaying-multivariate-data-and-measures-of-distance.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multivariate-normal-distribution.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
